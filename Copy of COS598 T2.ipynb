{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"111FCmT-OLFmX-1h-FaLf7-Ue6kMiAhrg","timestamp":1682272009250}],"mount_file_id":"111FCmT-OLFmX-1h-FaLf7-Ue6kMiAhrg","authorship_tag":"ABX9TyNJpsDF4KVRHVMuYkrF0QJQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#!pip install pyspark"],"metadata":{"id":"sWimk152tkdH","executionInfo":{"status":"ok","timestamp":1682265063098,"user_tz":300,"elapsed":248,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# COS 598 Homework 3 - Gregory Roberts"],"metadata":{"id":"hn1Ek8SvTfXm"}},{"cell_type":"code","execution_count":117,"metadata":{"id":"Qi1YFtf1tcBo","executionInfo":{"status":"ok","timestamp":1682268977075,"user_tz":300,"elapsed":138,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"outputs":[],"source":["import pandas as pd\n","from pyspark import SparkConf, SparkContext\n","import pyspark.sql as psql\n","from pyspark.sql import SQLContext\n","import pyspark.sql.functions as F\n","import pyspark.sql.types as T\n","from operator import add\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"markdown","source":["# Task 2\n","-----"],"metadata":{"id":"Ts0EFeX1TUPd"}},{"cell_type":"code","source":["conf = SparkConf().setMaster(\"local\").setAppName(\"PageRank\")\n","sc = SparkContext.getOrCreate(conf=conf)\n","sqlc = SQLContext.getOrCreate(sc)"],"metadata":{"id":"XtStUMcIuAfG","executionInfo":{"status":"ok","timestamp":1682269674142,"user_tz":300,"elapsed":127,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["# Read file into Spark RDD\n","rdd = sc.textFile(\"/content/drive/MyDrive/link_data.txt\")\n","# Print RDD\n","print(rdd.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tADjqrJM3ZdP","executionInfo":{"status":"ok","timestamp":1682265079666,"user_tz":300,"elapsed":3736,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"29b055e5-cb10-45f2-b624-46c43828123c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['0 2', '2 0', '1 2', '1 3', '3 2']\n"]}]},{"cell_type":"code","source":["# Reduce to X instances and map Y's to X\n","linksRDD = rdd.map(lambda x: tuple(x.split(\" \"))).map(lambda x: (x[0], [x[1]])).reduceByKey(lambda x, y: x+y)\n","# Print RDD\n","print(linksRDD.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8k6e3skSuEGv","executionInfo":{"status":"ok","timestamp":1682265081939,"user_tz":300,"elapsed":2285,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"bafdc7ec-fcb8-44bd-f1a9-006f639846d8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[('0', ['2']), ('2', ['0']), ('1', ['2', '3']), ('3', ['2'])]\n"]}]},{"cell_type":"code","source":["# 1) Initialize the page rank of every node as 1.\n","\n","ranksRDD = linksRDD.map(lambda x: (x[0], 1.0))\n","# Print RDD\n","print(ranksRDD.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IgEs6sjA2VCJ","executionInfo":{"status":"ok","timestamp":1682265081939,"user_tz":300,"elapsed":7,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"a1ad3080-0999-4d80-997c-4dde020a792d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[('0', 1.0), ('2', 1.0), ('1', 1.0), ('3', 1.0)]\n"]}]},{"cell_type":"code","source":["# 2) During each iteration, let vertex v contribute rank(v)/|neighbors(v)| to its neighboring vertices, \n","#    where rank(v) is the current page rank of vertex v and |neighbors(v)| denotes the number of vertices \n","#    to which vertex v links (i.e., the number of outgoing edges of vertex v).\n","\n","# This function takes elements from the joined datasets (linksRDD and ranksRDD)\n","# and computes the contribution to each outgoing link based on the current rank.\n","def computeContribs(node_rank):\n","    # Separates links and ranks\n","    _, (links, rank) = node_rank\n","    # Counts number of links\n","    nb_links = len(links)\n","    # Loop through links\n","    for link in links:\n","        # For each link divide rank by number of links\n","        yield link, rank / nb_links"],"metadata":{"id":"bdU8asPlBaYy","executionInfo":{"status":"ok","timestamp":1682265081940,"user_tz":300,"elapsed":5,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 4) Repeat steps 2 and 3 k times (you may set k = 10).\n","\n","for iteration in range(10):\n","    # Compute contributions of each node where it links to\n","    contribs = linksRDD.join(ranksRDD).flatMap(computeContribs)\n","    # Use a full outer join to make sure, that not well connected nodes aren't dropped\n","    contribs = linksRDD.fullOuterJoin(contribs).mapValues(lambda x : x[1] or 0.0)\n","    # Sum up all contributions per link\n","    ranksRDD = contribs.reduceByKey(add)\n","    # Re-calculate ranks\n","    # 3) Set each vertex’s rank to 0.15 + 0.85 × (contributions from all vertices that have \n","    #    edges pointing to the current vertex), where the contributions are computed in step 2.\n","    ranksRDD = ranksRDD.mapValues(lambda rank: rank * 0.85 + 0.15)"],"metadata":{"id":"tWKmbahjS-cb","executionInfo":{"status":"ok","timestamp":1682265082865,"user_tz":300,"elapsed":929,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 5) In the end, divide the page rank of every vertex by the total number of \n","#    vertices we have in the input graph.\n","\n","# Get the count of the original vertices\n","N = rdd.count()\n","# Divide each rank by the count\n","ranksRDD2 = ranksRDD.mapValues(lambda rank: rank / N)"],"metadata":{"id":"9hgaVx6Hs45D","executionInfo":{"status":"ok","timestamp":1682265083018,"user_tz":300,"elapsed":155,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Your implementation should output a text file, where each line contains a vertex and its \n","# page rank. With the test input text file shown above, your output text file should look like:\n","#    0 <page rank of 0>\n","#    1 <page rank of 1>\n","#    2 <page rank of 2>\n","#    3 <page rank of 3>\n","\n","# Loop through RDD by sorted link and rank\n","for (link, rank) in sorted(ranksRDD2.collect()):\n","    # Print sorted link and rank\n","    print(\"%s %s\" % (link, rank))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWe22oE5yVqO","executionInfo":{"status":"ok","timestamp":1682266663647,"user_tz":300,"elapsed":1079,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"fc927977-e188-42e1-f208-53194cbcd605"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["0 0.36844926958806634\n","1 0.03\n","2 0.35880073041193344\n","3 0.042749999999999996\n"]}]},{"cell_type":"markdown","source":["# Task 3\n","-----"],"metadata":{"id":"f2rXplM5Tp5K"}},{"cell_type":"code","source":["# (a) Create a Spark data frame from the RDD containing the page ranks of the vertices 0, 1, 2, and 3 computed in Task 1.\n","df = ranksRDD2.toDF"],"metadata":{"id":"og1fKJjNuAhs","executionInfo":{"status":"ok","timestamp":1682266731733,"user_tz":300,"elapsed":163,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# assuming the spark environemnt is set and sc is spark.sparkContext \n","sqlContext = SQLContext(sc)\n","# Create dataframe from RDD\n","df = sqlContext.createDataFrame(ranksRDD2)\n","df.createOrReplaceTempView(\"ranksRDD2\")"],"metadata":{"id":"bWCfm0t2THOb","executionInfo":{"status":"ok","timestamp":1682266781024,"user_tz":300,"elapsed":127,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["# df Type is PySpark SQL dataframe\n","print(type(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XFPacQN5bkP","executionInfo":{"status":"ok","timestamp":1682266782252,"user_tz":300,"elapsed":148,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"c8480650-52e4-4f59-a34d-a1875fcd29ff"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pyspark.sql.dataframe.DataFrame'>\n"]}]},{"cell_type":"code","source":["# Show entire PySpark SQL dataframe\n","print(df.show())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sP35K9CPZ1CX","executionInfo":{"status":"ok","timestamp":1682266822814,"user_tz":300,"elapsed":1775,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"555b8eaa-384c-4899-b3d0-6f8b02fa8140"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| _1|                  _2|\n","+---+--------------------+\n","|  2| 0.35880073041193344|\n","|  1|                0.03|\n","|  3|0.042749999999999996|\n","|  0| 0.36844926958806634|\n","+---+--------------------+\n","\n","None\n"]}]},{"cell_type":"code","source":["sqlc.sql(\"SELECT MAX(_2) as maxval FROM ranksRDD2\").first().asDict()['maxval']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdzSsNvyOP35","executionInfo":{"status":"ok","timestamp":1682271970266,"user_tz":300,"elapsed":1559,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"8a29f557-e116-4ea7-ffa4-1152a6cbcbda"},"execution_count":140,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.36844926958806634"]},"metadata":{},"execution_count":140}]},{"cell_type":"code","source":["# (b) Write a Spark SQL query to find the page rank of vertex 2. Print it to the screen.\n","\n","# Filter column _1 equal to 2, and select only column 2\n","print(df.filter(df._1 == 2).select(\"_2\").show())\n","sqlc.sql(\"SELECT MAX(_2) as maxval FROM ranksRDD2\").first().asDict()['maxval']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZq0O4doTHWi","executionInfo":{"status":"ok","timestamp":1682268671375,"user_tz":300,"elapsed":1876,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"1ec18d45-be93-4fce-d732-c4c39e1b08df"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------+\n","|                 _2|\n","+-------------------+\n","|0.35880073041193344|\n","+-------------------+\n","\n","None\n"]}]},{"cell_type":"code","source":["# (c) Write a Spark SQL query to find the vertex with the largest page rank. Print both the vertex ID and its page rank.\n","\n","max_high = df.select(F.max(F.col('_2'))).collect()[0]['max(_2)']\n","df.filter(F.col('_2') == max_high).orderBy(F.col('_1').desc()).show()"],"metadata":{"id":"1Jg3mvRWTHbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.registerTempTable(\"df_table\")\n","sqlc.sql(\"SELECT MAX(_2) as maxval FROM df_table\").first().asDict()['maxval']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g99gcDEqDHeD","executionInfo":{"status":"ok","timestamp":1682271926038,"user_tz":300,"elapsed":2395,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"0167efdc-ed75-448d-9107-903e6f0de9a4"},"execution_count":139,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.36844926958806634"]},"metadata":{},"execution_count":139}]}]}