{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOIc+l9Oxu4kpV25CsZAVcT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import plotly as plot\n","from sklearn.preprocessing import scale\n","from plotnine import *\n","from plotnine.data import *\n","from plotnine.data import economics\n","from plotnine import ggplot, aes, geom_line\n","from plotnine.geoms.geom_boxplot import geom_boxplot\n","from plotnine.geoms.geom_point import geom_point\n","from plotnine.geoms.geom_rug import coord_flip\n","from plotnine.labels import labs\n","from google.colab import drive"],"metadata":{"id":"9-VT62SOXxm0","executionInfo":{"status":"ok","timestamp":1670186079040,"user_tz":360,"elapsed":6844,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Check if file already exists\n","matches = [match for match in os.listdir() if \"messidor_features.arff\" in match]\n","\n","# If file is missing, then download it\n","if not matches:\n","  !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00329/messidor_features.arff"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sE_8UouB0Pl3","executionInfo":{"status":"ok","timestamp":1670034589758,"user_tz":360,"elapsed":580,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"62112631-2e4d-49dc-ba94-40285b852a8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-03 02:29:49--  https://archive.ics.uci.edu/ml/machine-learning-databases/00329/messidor_features.arff\n","Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n","Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 117224 (114K) [application/x-httpd-php]\n","Saving to: ‘messidor_features.arff’\n","\n","messidor_features.a 100%[===================>] 114.48K  --.-KB/s    in 0.1s    \n","\n","2022-12-03 02:29:49 (806 KB/s) - ‘messidor_features.arff’ saved [117224/117224]\n","\n"]}]},{"cell_type":"code","source":["# Load the data and convert to dataframe.\n","from scipy.io import arff\n","data = arff.loadarff('/content/messidor_features.arff')\n","df = pd.DataFrame(data[0])"],"metadata":{"id":"ESTwheIx0i6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["col_names = ['q', 'ps', 'nma.a', 'nma.b', 'nma.c', 'nma.d', 'nma.e', 'nma.f', \n","             'nex.a', 'nex.b', 'nex.c', 'nex.d', 'nex.e', 'nex.f', 'nex.g', \n","             'nex.h', 'dd', 'dm', 'amfm', 'class_label']\n","\n","df.columns = col_names"],"metadata":{"id":"_YRgsHpfaRXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numericFeats = list(range(3,17))\n","# eyeFeats = list(range(17,19))"],"metadata":{"id":"70LDApmqlyi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df[, c(numericFeats, eyeFeats)] = scale(df[, c(numericFeats, eyeFeats)])\n","df.iloc[:, 2:17] = scale(df.iloc[:, 2:17])\n","\n","# df$class = as.factor(df$class)\n","# df['new_factor'], _ = pd.factorize(df['old_categorical'], sort=True)\n","\n","df[\"class_label\"], _ = pd.factorize(df[\"class_label\"], sort=True)"],"metadata":{"id":"dAej4ePioTKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# long = melt(df[,c(1:ncol(df)-1)])\n","long = pd.melt(df.iloc[:, 0:len(df.columns)-1], col_level=0)"],"metadata":{"id":"7y63aT9v-yYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ggplot(long) + geom_boxplot(aes(variable, value)) + coord_flip() + labs(title=\"Unimodal feature distribution\", x='Feature', y='Scaled value')\n","ggplot(long) + geom_boxplot(aes(x='variable', y='value')) + coord_flip() + labs(title=\"Unimodal feature distribution\", x='Feature', y='Scaled value')"],"metadata":{"id":"W1Xca78GTKUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ggcorr(df) + labs(title=\"Feature covariance matrix\")\n","df.corr().style.background_gradient(cmap='PuBu')\n"],"metadata":{"id":"V2-Sf-WTTOUY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ggplot(df) + geom_point(aes(x=\"nma.a\", y=\"nma.b\", color=\"class_label\")) + facet_wrap(\"~amfm\")"],"metadata":{"id":"nEywArh2TQeg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ggplot(df) + geom_point(aes(x=\"nma.a\", y=\"nma.f\", color=\"class_label\")) + facet_wrap(\"~amfm\")"],"metadata":{"id":"L_jvZmMETSxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ggplot(df) + geom_point(aes(x=\"nex.a\", y=\"nex.b\", color=\"class_label\")) + facet_wrap(\"~amfm\")"],"metadata":{"id":"RXxzM7ObTUsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ggplot(df) + geom_point(aes(x=\"nex.a\", y=\"nex.h\", color=\"class_label\")) + facet_wrap(\"~amfm\")"],"metadata":{"id":"AHVNB1fpTXOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ggplot(df) + geom_point(aes(x=\"nma.a\", y=\"nex.h\", color=\"class_label\")) + facet_wrap(\"~amfm\")"],"metadata":{"id":"dCUhnGj2TZdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ecOn0Sln1Ktw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NnyIcWoJ1Kwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PbEYlLCb1K1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"90Sq5E3R1K43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["helpers.result = function(pred, real){\n","    return(data.frame(pred=pred, real=real, ok=(pred==real)))\n","}\n","\n","fitpredict.svm = function(formula, trainingSet, validationSet, kernel=\"polynomial\", degree=2, coef0=1){\n","    model = svm(formula, trainingSet, kernel=kernel, degree=degree, coef0=coef0)\n","    pred = as.integer(predict(model, validationSet))\n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(pred, real))\n","}\n","\n","fitpredict.forest = function(formula, trainingSet, validationSet, ntree=100){\n","    model = randomForest(formula, trainingSet, ntree=ntree)\n","    pred = as.integer(predict(model, validationSet))\n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(pred, real))\n","}\n","\n","fitpredict.knn = function(formula, trainingSet, validationSet, k=5){\n","    cols = all.vars(formula)[2:length(all.vars(formula))]\n","    pred = as.integer(knn(trainingSet[,cols], validationSet[,cols], trainingSet$class, k=k))\n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(pred, real))\n","}\n","\n","fitpredict.adaboost = function(formula, trainingSet, validationSet, boos=TRUE, mfinal=10, coeflearn='Breiman'){\n","    model = boosting(formula, trainingSet, boos=boos, mfinal=mfinal, coeflearn=coeflearn)\n","    pred = as.integer(predict.boosting(model, validationSet)$class)+1\n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(pred, real))\n","}\n","\n","fitpredict.nnet = function(formula, trainingSet, validationSet, size=10){\n","    model = nnet(formula, trainingSet, size=size, trace=FALSE)\n","    pred = as.integer(round(predict(model, validationSet)))+1\n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(pred, real))\n","}\n","\n","fitpredict.naiveBayes = function(formula, trainingSet, validationSet){\n","    model = naiveBayes(formula, trainingSet)\n","    pred = as.integer(predict(model, validationSet))\n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(pred, real))\n","}\n","\n","fitpredict.lda = function(formula, trainingSet, validationSet){\n","    model = lda(formula, trainingSet)\n","    pred = as.integer(data.frame(predict(model, validationSet))$class)\n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(pred, real))\n","}"],"metadata":{"id":"CW7JgLNYbgEs","colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"status":"error","timestamp":1670034774250,"user_tz":360,"elapsed":96,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"4ba3a7ee-b031-4fb4-9b3a-be53ff6e3bce"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-6c3e68387d1f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    helpers.result = function(pred, real){\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["perf.auc = function(yy){\n","    \n","    return(performance(prediction(yy$real, yy$pred), \"auc\")@y.values[[1]])\n","}"],"metadata":{"id":"6hWaCopOblfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kfoldValidate = function(formula, data, learner, performance, ...){\n","    \n","    k=10\n","    ks = c(1:k)\n","    folds = createFolds(data$class, k, list=FALSE)\n","    result = rep(0, k)\n","    \n","    for (i in ks){\n","        \n","        trainingKs = ks[ks!=i]\n","        validationKs = ks[ks==i]\n","        trainingSet = data[which(folds %in% trainingKs), ]\n","        validationSet = data[which(folds %in% validationKs), ]\n","        result[i] = performance(learner(formula, trainingSet, validationSet, ...))\n","    }\n","    \n","    return(list(mean=mean(result), sd=sd(result), results=c(result)))\n","}"],"metadata":{"id":"INSbTOyRbprE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1 = as.formula(class ~ ps + \n","                    nma.a + nma.b + nma.c + nma.d + nma.e + nma.f + \n","                    nex.a + nex.b + nex.c + nex.d + nex.e + nex.g + nex.f + nex.h + \n","                    dd + dm + amfm)\n","\n","resultsF1v = c(\n","    svm        = kfoldValidate(f1, data=df, learner=fitpredict.svm,        performance=perf.auc)$mean,\n","    forest     = kfoldValidate(f1, data=df, learner=fitpredict.forest,     performance=perf.auc)$mean,\n","    knn        = kfoldValidate(f1, data=df, learner=fitpredict.knn,        performance=perf.auc)$mean,\n","    adaboost   = kfoldValidate(f1, data=df, learner=fitpredict.adaboost,   performance=perf.auc)$mean,\n","    nnet       = kfoldValidate(f1, data=df, learner=fitpredict.nnet,       performance=perf.auc)$mean,\n","    naiveBayes = kfoldValidate(f1, data=df, learner=fitpredict.naiveBayes, performance=perf.auc)$mean,\n","    lda        = kfoldValidate(f1, data=df, learner=fitpredict.lda,        performance=perf.auc)$mean\n",")\n","resultsF1 = data.frame(f1_AUC=resultsF1v)\n","kable(resultsF1, caption=\"Model performance for F1\")"],"metadata":{"id":"ictq9VgibqSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols = all.vars(f1)[2:length(all.vars(f1))]\n","fit = prcomp(df[,cols], center=T, scale=T)\n","\n","df = cbind(df, fit$x)"],"metadata":{"id":"OAQfq--9bs8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f2 = as.formula(class ~ PC1 + PC2 +  PC3 +  PC4 +  PC5 +  PC6 +  PC7 + PC8 + PC9 + PC10 + PC11 + PC12 )\n","\n","resultsF2v = c(\n","    svm        = kfoldValidate(f2, data=df, learner=fitpredict.svm,        performance=perf.auc)$mean,\n","    forest     = kfoldValidate(f2, data=df, learner=fitpredict.forest,     performance=perf.auc)$mean,\n","    knn        = kfoldValidate(f2, data=df, learner=fitpredict.knn,        performance=perf.auc)$mean,\n","    adaboost   = kfoldValidate(f2, data=df, learner=fitpredict.adaboost,   performance=perf.auc)$mean,\n","    nnet       = kfoldValidate(f2, data=df, learner=fitpredict.nnet,       performance=perf.auc)$mean,\n","    naiveBayes = kfoldValidate(f2, data=df, learner=fitpredict.naiveBayes, performance=perf.auc)$mean,\n","    lda        = kfoldValidate(f2, data=df, learner=fitpredict.lda,        performance=perf.auc)$mean\n",")\n","\n","resultsF2 = data.frame(f2_AUC=resultsF2v)\n","results = cbind(resultsF2, resultsF1)\n","results$improvement=results$f2_AUC - results$f1_AUC\n","kable(results, caption=\"Model performance for F1 vs F2\")"],"metadata":{"id":"RITD30stbvKO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f3 = as.formula(class ~ ps + \n","                    nma.a + nma.b + nma.c + nma.d + nma.e + nma.f + \n","                    nex.a + nex.b + nex.c + nex.d + nex.e + nex.g + nex.f + nex.h + \n","                    dd + dm + amfm + \n","                    PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12)\n","\n","\n","resultsF3v = c(\n","    svm        = kfoldValidate(f3, data=df, learner=fitpredict.svm,        performance=perf.auc)$mean,\n","    forest     = kfoldValidate(f3, data=df, learner=fitpredict.forest,     performance=perf.auc)$mean,\n","    knn        = kfoldValidate(f3, data=df, learner=fitpredict.knn,        performance=perf.auc)$mean,\n","    adaboost   = kfoldValidate(f3, data=df, learner=fitpredict.adaboost,   performance=perf.auc)$mean,\n","    nnet       = kfoldValidate(f3, data=df, learner=fitpredict.nnet,       performance=perf.auc)$mean,\n","    naiveBayes = kfoldValidate(f3, data=df, learner=fitpredict.naiveBayes, performance=perf.auc)$mean,\n","    lda        = kfoldValidate(f3, data=df, learner=fitpredict.lda,        performance=perf.auc)$mean\n",")\n","\n","resultsF3 = data.frame(f3_AUC=resultsF3v)\n","results = cbind(resultsF3, resultsF2)\n","results$improvement=results$f3_AUC - results$f2_AUC\n","kable(results, caption=\"Model performance for F2 vs F3\")"],"metadata":{"id":"8TVBT3PZbxj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.5, 0.5))\n","\n","trainingDf   = df[ind==1,]\n","validationDf = df[ind==2,]"],"metadata":{"id":"ub0eNs_ybz80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selectModel = function(formula, data, learner, performance, hyperParameters){\n","    \n","    if(is.null(hyperParameters)){\n","    \n","        return(list(model=NULL, data=NULL))\n","    }\n","    \n","    results = cbind(hyperParameters, performance=rep(0, nrow(hyperParameters)))\n","    \n","    for (i in 1:nrow(results)){\n","        hyper = c(hyperParameters[i, ])\n","        arguments = c(list(formula=formula, data=data, learner=learner, performance=performance), hyper)\n","        results[i, 'performance'] = do.call(kfoldValidate, arguments)$mean\n","    }\n","    \n","    selectedModel = results[which.max(results$performance), colnames(hyperParameters)]\n","    names(selectedModel) = colnames(hyperParameters)\n","    \n","    return(list(model=as.list(selectedModel), data=results))\n","}"],"metadata":{"id":"26eI4wgRT65o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["candidateParameters = list(\n","    svm        = buildHyperDf(kernel=c(\"polynomial\"), degree=c(1,2), coef0=seq(1, 3, by=1)),\n","    forest     = buildHyperDf(ntree=seq(10, 20, by=10)),\n","    knn        = buildHyperDf(k=seq(2, 4, by=1)),\n","    nnet       = buildHyperDf(size=seq(1, 3, by=1))\n",")\n","\n","params = list(\n","    svm    = selectModel(f3, trainingDf, fitpredict.svm,    perf.auc, candidateParameters$svm),\n","    forest = selectModel(f3, trainingDf, fitpredict.forest, perf.auc, candidateParameters$forest),\n","    knn    = selectModel(f3, trainingDf, fitpredict.knn,    perf.auc, candidateParameters$knn),\n","    nnet   = selectModel(f3, trainingDf, fitpredict.nnet,   perf.auc, candidateParameters$nnet)\n",")\n","\n","kable(params$svm$data[order(-params$svm$data$performance),], \n","    caption=\"SVM performance for different variable combinations\"\n",")"],"metadata":{"id":"47n7HAdbT9AB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svmResult = kfoldValidate(f3, validationDf, learner=fitpredict.svm, performance=perf.auc, \n","    kernel=params$svm$model$kernel,\n","    degree=params$svm$model$degree,\n","    coef0=params$svm$model$coef0\n",")$mean\n","\n","\n","kable(params$forest$data[order(-params$forest$data$performance),], \n","    caption=\"Random Forest performance for different variable combinations\"\n",")"],"metadata":{"id":"roavek__T_GJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["forestResult = kfoldValidate(f3, validationDf, learner=fitpredict.forest, performance=perf.auc, \n","    ntree=params$forest$model$ntree\n",")$mean\n","\n","\n","kable(params$knn$data[order(-params$knn$data$performance),], \n","    caption=\"k-NN performance for different variable combinations\"\n",")"],"metadata":{"id":"zED_805OUCMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["knnResult = kfoldValidate(f3, validationDf, learner=fitpredict.knn, performance=perf.auc, \n","    k=params$knn$model$k\n",")$mean\n","\n","kable(params$nnet$data[order(-params$nnet$data$performance),], \n","    caption=\"ANN performance for different variable combinations\"\n",")"],"metadata":{"id":"eqM0RuntUEXp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nnetResult = kfoldValidate(f3, validationDf, learner=fitpredict.nnet, performance=perf.auc, \n","    size=params$nnet$model$size\n",")$mean\n","\n","kable(data.frame(\n","    model=c('SVM', 'Random Forest', 'k-NN', 'ANN'), \n","    auc=c(svmResult, forestResult, knnResult, nnetResult)),\n","    caption=\"Model performance for the best model paramenters for each model class\"\n",")"],"metadata":{"id":"FXxhoX1TUGgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selectModelFormula = function(formula, data, learner, performance, hyperParameters=NULL){\n","    \n","    class = all.vars(formula)[1]\n","    features = all.vars(formula)[2:length(all.vars(formula))]\n","    \n","    results = data.frame(left=c('full', features), result=rep(NA, length(features)+1))\n","    \n","    if(!is.null(hyperParameters)){\n","        \n","        selectedParameters = selectModel(formula, data, learner, performance, hyperParameters)$model\n","        \n","        arguments = c(\n","            list(formula=formula, data=data, learner=learner, performance=performance),\n","            selectedParameters    \n","        )\n","        \n","    } else {\n","        \n","        selectedParameters = NULL\n","        arguments = list(formula=formula, data=data, learner=learner, performance=performance)\n","    }\n","    \n","    bestRoundPerformance = tryCatch(do.call(kfoldValidate, arguments)$mean, error=function(cond){ return(0) })\n","    featureLeftOut = NULL\n","    bestRoundParameters = selectedParameters\n","    \n","    results[results$left=='full', 'result'] = bestRoundPerformance\n","    \n","    for(i in 1:length(features)){\n","        \n","        try({\n","            \n","            roundFormula = as.formula(paste(class, \"~\", paste(features[-c(i)], collapse=\"+\")))\n","            \n","            if(!is.null(hyperParameters)){\n","                \n","                arguments = c(\n","                    list(formula=roundFormula, data=data, learner=learner, performance=performance),\n","                    bestRoundParameters    \n","                )\n","                \n","            } else {\n","                \n","                bestRoundParameters = NULL\n","                arguments = list(formula=formula, data=data, learner=learner, performance=performance)\n","            }\n","            \n","            roundPerformance = do.call(kfoldValidate, arguments)$mean\n","            results[results$left==features[i], 'result'] = roundPerformance\n","        \n","            if(roundPerformance > bestRoundPerformance){\n","                \n","                bestRoundPerformance = roundPerformance\n","                featureLeftOut = i\n","            }\n","        })\n","    }\n","\n","    if(!is.null(featureLeftOut) && length(features) > 2){\n","        \n","        selectedFormula = as.formula(paste(class, \"~\", paste(features[-c(featureLeftOut)], collapse=\"+\")))    \n","        return(selectModelFormula(selectedFormula, data, learner, performance, hyperParameters))\n","        \n","    } else {\n","        \n","        return(list(\n","            formula=formula,\n","            params=bestRoundParameters\n","        ))\n","    }\n","}"],"metadata":{"id":"zCh_cNy5UJPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = selectModelFormula(f3, trainingDf, fitpredict.knn, perf.auc, candidateParameters$knn)\n","\n","kable(data.frame(features=all.vars(params$formula)), caption=\"Selected features using leave-one-out algorithm\")"],"metadata":{"id":"eJ2K8JjJUN7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kable(data.frame(params$params), caption=\"Selected model parameters\")"],"metadata":{"id":"7rZIzZJpUQf5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = kfoldValidate(params$formula, validationDf, learner=fitpredict.knn, performance=perf.auc, \n","    k=params$params\n",")$mean\n","\n","kable(data.frame(auc=result), caption=\"k-NN performance for the optimized formula and model\")"],"metadata":{"id":"zZ20dfVDUSx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fitpredict.votingEnsemble = function(formula, trainingSet, validationSet, learners, params){\n","    \n","    ensembleResults = data.frame(majority=rep(NA, nrow(validationSet)))\n","    \n","    for (name in names(learners)){\n","        \n","        if(!is.null(params)){\n","            \n","            arguments = c(\n","                list(params[name][[1]]$formula, trainingSet=trainingSet, validationSet=validationSet),\n","                params[name][[1]]$params\n","            )\n","            \n","        } else {\n","            \n","            arguments = list(params[name][[1]]$formula, trainingSet=trainingSet, validationSet=validationSet)\n","        }\n","        \n","        modelResult = list(predicted=do.call(learners[name][[1]], arguments)$pred)\n","        names(modelResult) = c(name)\n","        ensembleResults = cbind(ensembleResults, modelResult)\n","    }\n","    \n","    ensembleResults$majority = apply(ensembleResults[, names(learners)], 1, FUN=function(x){ \n","        as(names(which.max(table(x))), mode(x))  \n","    })\n","    \n","    real = as.integer(validationSet[,all.vars(formula)[1]])\n","    return(helpers.result(ensembleResults$majority, real))\n","}"],"metadata":{"id":"IARdnwXeUVMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["selectVotingEnsemble = function(formula, data, performance, learners, learnersParams){\n","    \n","    learnerNames = names(learners)\n","    results = data.frame(left=c('full', learnerNames), result=rep(NA, length(learners)+1))\n","    \n","    bestRoundPerformance = kfoldValidate(formula, data, fitpredict.votingEnsemble, performance=perf.auc,\n","        learners=learners, \n","        params=learnersParams\n","    )$mean    \n","    \n","    modelLeftOut = NULL\n","    \n","    results[results$left=='full', 'result'] = bestRoundPerformance\n","    \n","    for(i in 1:length(learnerNames)){\n","        \n","        try({\n","                \n","            roundPerformance = kfoldValidate(formula, data, fitpredict.votingEnsemble, perf.auc,\n","              learners=learners[-c(i)], \n","              params=learnersParams[-c(i)]\n","            )$mean\n","            \n","            results[results$left==learnerNames[i], 'result'] = roundPerformance\n","            \n","            if(roundPerformance > bestRoundPerformance){\n","                \n","                bestRoundPerformance = roundPerformance\n","                modelLeftOut = i\n","            }\n","        })\n","    }\n","    \n","    if(!is.null(modelLeftOut) && length(learners) > 2){\n","        \n","        return(selectVotingEnsemble(formula, data, performance,\n","            learners[-c(modelLeftOut)], \n","            learnersParams[-c(modelLeftOut)]\n","        ))\n","        \n","    } else {\n","        \n","        return(learners)\n","    }\n","}"],"metadata":{"id":"zSukZINlUYjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learners = list(\n","    svm        = fitpredict.svm,\n","    forest     = fitpredict.forest,\n","    knn        = fitpredict.knn,\n","    nnet       = fitpredict.nnet,\n","    naiveBayes = fitpredict.naiveBayes,\n","    lda        = fitpredict.lda\n",")\n","\n","candidateParameters = list(\n","    svm        = list(formula=f3, params=NULL),\n","    forest     = list(formula=f3, params=NULL),\n","    knn        = list(formula=f3, params=NULL),\n","    nnet       = list(formula=f3, params=NULL),\n","    naiveBayes = list(formula=f3, params=NULL),\n","    lda        = list(formula=f3, params=NULL)\n",")\n","\n","finalEnsemble = selectVotingEnsemble(f3, trainingDf, perf.auc, learners, candidateParameters)\n","\n","kable(data.frame(models=names(finalEnsemble)), caption = \"Models considered by the naive ensemble\")"],"metadata":{"id":"vBApt7pvUcCZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = kfoldValidate(f3, validationDf, fitpredict.votingEnsemble, perf.auc, finalEnsemble,\n","    candidateParameters[names(finalEnsemble)]\n",")$mean\n","\n","kable(data.frame(auc=result), caption=\"Naive Ensemble Performance\")"],"metadata":{"id":"hzWv5j3JUf_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["candidateParameters = list(\n","    svm        = buildHyperDf(kernel=c(\"polynomial\", \"radial\"), degree=c(1,2), coef0=c(1,10,50,100)),\n","    forest     = buildHyperDf(ntree=seq(100, 500, by=100)),\n","    knn        = buildHyperDf(k=seq(2, 30, by=2)),\n","    nnet       = buildHyperDf(size=seq(5, 20, by=5))\n",")\n","\n","svmParams        = selectModelFormula(f3, trainingDf, fitpredict.svm,        perf.auc, candidateParameters$svm)\n","forestParams     = selectModelFormula(f3, trainingDf, fitpredict.forest,     perf.auc, candidateParameters$forest)\n","nnetParams       = selectModelFormula(f3, trainingDf, fitpredict.nnet,       perf.auc, candidateParameters$nnet)\n","knnParams        = selectModelFormula(f3, trainingDf, fitpredict.knn,        perf.auc, candidateParameters$knn)\n","naiveBayesParams = selectModelFormula(f3, trainingDf, fitpredict.naiveBayes, perf.auc)\n","ldaParams        = selectModelFormula(f3, trainingDf, fitpredict.lda,        perf.auc)\n","adaboostParams   = list(\n","    formula=f3,\n","    params=NULL\n",")\n","\n","learners = list(\n","    svm        = fitpredict.svm,\n","    forest     = fitpredict.forest,\n","    knn        = fitpredict.knn,\n","    nnet       = fitpredict.nnet,\n","    adaboost   = fitpredict.adaboost,\n","    naiveBayes = fitpredict.naiveBayes,\n","    lda        = fitpredict.lda\n",")\n","\n","candidateModels = list(\n","    svm        = svmParams,\n","    forest     = forestParams,\n","    knn        = knnParams,\n","    nnet       = nnetParams,\n","    adaboost   = adaboostParams,\n","    naiveBayes = naiveBayesParams,\n","    lda        = ldaParams\n",")\n","\n","finalLearners = selectVotingEnsemble(f3, trainingDf, perf.auc, learners, candidateModels)\n","\n","kable(data.frame(models=names(finalEnsemble)), caption = \"Models considered by the final ensemble\")"],"metadata":{"id":"PJ3xb2kiUiBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultTraining = kfoldValidate(f3, trainingDf, fitpredict.votingEnsemble, perf.auc, finalLearners,\n","    candidateModels[names(finalLearners)]\n",")$mean\n","\n","resultValidation = kfoldValidate(f3, validationDf, fitpredict.votingEnsemble, perf.auc, finalLearners,\n","    candidateModels[names(finalLearners)]\n",")$mean\n","\n","resultComplete = kfoldValidate(f3, df, fitpredict.votingEnsemble, perf.auc, finalLearners,\n","    candidateModels[names(finalLearners)]\n",")$mean\n","\n","kable(data.frame(\n","    set=c('Training', 'Validation', 'All'), \n","    auc=c(resultTraining, resultValidation, resultComplete)\n","), caption=\"Final ensemble performance\")"],"metadata":{"id":"k7lnxogcUl5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"esTwBpXDUoRx"},"execution_count":null,"outputs":[]}]}