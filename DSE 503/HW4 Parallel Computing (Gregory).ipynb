{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW4 Parallel Computing (Gregory).ipynb","provenance":[{"file_id":"1Z0IW7b6xGMDJ7bqhqnaAQnCLjcdJkxJO","timestamp":1647134957182}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Your Name:  Gregory Roberts\n","\n","Submission Instruction:\n","* Instruction: make a copy of this CoLab file and share it with me (Yifeng.Zhu@maine.edu).\n","* Deadline: Midnight, Sunday, April 2\n"],"metadata":{"id":"6l93mpX3DmeN"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bClHRKnEcB3E","executionInfo":{"status":"ok","timestamp":1651086457738,"user_tz":300,"elapsed":59257,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"fb6d26b8-d276-454f-b3b5-b8edf014fe65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mpi4py\n","  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 5.4 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185277 sha256=f3569827b44add27c4d892f94f7224ec2d37f81d0dd2f48950c0c5ae045887e2\n","  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-3.1.3\n"]}],"source":["!pip install mpi4py"]},{"cell_type":"markdown","source":["#Question 1: Point-to-point communication"],"metadata":{"id":"hk14eH9XBCn7"}},{"cell_type":"markdown","source":["Is there any problem in the following code? If so, how to fix it?"],"metadata":{"id":"I7sWxNKhDTdV"}},{"cell_type":"code","source":["%%file q1.py\n","from mpi4py import MPI\n","\n","comm = MPI.COMM_WORLD\n","rank = comm.Get_rank()\n","\n","if rank==1:\n","    data_send= \"a\"\n","    destination_process = 2\n","    source_process = 2\n","\n","    comm.send(data_send, dest=destination_process)\n","    data_received = comm.recv(source=source_process)\n","    \n","    print (\"sending data %s \" %data_send + \\\n","           \"to process %d\" %destination_process)\n","    print (\"data received = %s\" %data_received)\n","\n","if rank==2:\n","    data_send= \"b\"\n","    destination_process = 1\n","    source_process = 1\n","\n","    comm.send(data_send, dest=destination_process)\n","    data_received = comm.recv(source=source_process)\n","    \n","    print (\"sending data %s :\" %data_send + \\\n","           \"to process %d\" %destination_process)\n","    print (\"data received = %s\" %data_received)\n"],"metadata":{"id":"h6r-IMmuC7_f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648923779409,"user_tz":300,"elapsed":134,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"71c9ad9e-9bd3-482e-c695-032e391eee13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing q1.py\n"]}]},{"cell_type":"code","source":["!mpirun --allow-run-as-root -n 4 python q1.py"],"metadata":{"id":"9h3HAro7DJZ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648923782663,"user_tz":300,"elapsed":604,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"d1e382d3-8aab-4cf1-ac32-d3085e6d0799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sending data a to process 2\n","data received = b\n","sending data b :to process 1\n","data received = a\n"]}]},{"cell_type":"markdown","source":["**Your answer:**  Changed the code so that the comm.send is before the comm.recv for both rank processes.\n"],"metadata":{"id":"SHvRjOIbDaB6"}},{"cell_type":"markdown","source":["# Question 2: Fix the bug of the following code"],"metadata":{"id":"ox8qkWQQcFIQ"}},{"cell_type":"markdown","source":["The following code is to implement a parallel matrix vector product. However, there are a large different between the parallel implementation and the result produced by numpy.dot. What is wrong with the code and how to fix it?"],"metadata":{"id":"19DJj189Bf2K"}},{"cell_type":"code","source":["# This code is used to generate the vector and matrix that will be used in the\n","# next section. These are then stored in files so that the values do not change\n","# each time the process iterates through the rank.\n","\n","import numpy as np\n","import os\n","\n","n = 400\n","\n","x = np.random.rand(n)     # Generate a vector     \n","A = np.random.rand(n, n)  # Generate a nxn matrix\n","\n","np.savetxt(fname=\"x_array.csv\", delimiter=\",\", X=x)\n","np.savetxt(fname=\"A_matrix.csv\", delimiter=\",\", X=A)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0VvWgkqF_jW","executionInfo":{"status":"ok","timestamp":1649034261064,"user_tz":300,"elapsed":4843,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"2b6ad4a5-e4c4-4d95-bc4e-626549d23f2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Numpy Version is  1.21.5\n"]}]},{"cell_type":"code","source":["%%file matvec.py\n","import numpy as np\n","from mpi4py import MPI\n","import os\n","\n","# Parallel matrix-vector product\n","def matvec(comm, A, x):\n","    size = comm.Get_size()\n","    rank = comm.Get_rank()\n","    m = A.shape[0] // size # local rows\n","    # every process gets a part of the data\n","    y_part = np.dot(A[rank * m:(rank+1)*m, :], x) \n","    # container for the result    \n","    y = np.zeros_like(x, dtype='double')     \n","    # collect results from the pool, write them to container y      \n","    comm.Allgather([y_part,  MPI.DOUBLE], [y, MPI.DOUBLE])    \n","    return y\n","\n","n = 400\n","comm = MPI.COMM_WORLD\n","rank = comm.Get_rank()\n","\n","print('comm.Get_size() ', comm.Get_size())\n","#x = np.random.rand(n)     # Generate a vector     \n","#A = np.random.rand(n, n)  # Generate a nxn matrix\n","x = np.loadtxt(fname=\"x_array.csv\", delimiter=\",\")\n","A = np.loadtxt(fname=\"A_matrix.csv\", delimiter=\",\")\n","\n","y_mpi = matvec(comm, A, x) # y_mpi = A * x\n","\n","if rank == 0: # check \n","  y = np.dot(A, x)      \n","  # compare the local and MPI results   \n","  # The output should be a very small value \n","  print(\"sum(y - y_mpi) = \", (y - y_mpi).sum()) \n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCJ1U_R8cTzU","executionInfo":{"status":"ok","timestamp":1651086371486,"user_tz":300,"elapsed":6,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"82596d93-be72-444d-bc4c-f7fb0f68b64e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing matvec.py\n"]}]},{"cell_type":"code","source":["!mpirun --allow-run-as-root -n 4 python3 matvec.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HflMbWWcaTD","executionInfo":{"status":"ok","timestamp":1651086639292,"user_tz":300,"elapsed":1081,"user":{"displayName":"Gregory Roberts","userId":"00352358460499938030"}},"outputId":"5aaad2eb-7129-4b2a-a58c-6f63e33cf921"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["comm.Get_size()  4\n","comm.Get_size()  4\n","comm.Get_size()  4\n","comm.Get_size()  4\n","Traceback (most recent call last):\n","  File \"matvec.py\", line 25, in <module>\n","    x = np.loadtxt(fname=\"x_array.csv\", delimiter=\",\")\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\", line 1067, in loadtxt\n","    fh = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 193, in open\n","    return ds.open(path, mode, encoding=encoding, newline=newline)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 533, in open\n","    raise IOError(\"%s not found.\" % path)\n","OSError: x_array.csv not found.\n","Traceback (most recent call last):\n","  File \"matvec.py\", line 25, in <module>\n","    x = np.loadtxt(fname=\"x_array.csv\", delimiter=\",\")\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\", line 1067, in loadtxt\n","    fh = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 193, in open\n","    return ds.open(path, mode, encoding=encoding, newline=newline)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 533, in open\n","    raise IOError(\"%s not found.\" % path)\n","OSError: x_array.csv not found.\n","Traceback (most recent call last):\n","  File \"matvec.py\", line 25, in <module>\n","    x = np.loadtxt(fname=\"x_array.csv\", delimiter=\",\")\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\", line 1067, in loadtxt\n","    fh = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 193, in open\n","    return ds.open(path, mode, encoding=encoding, newline=newline)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 533, in open\n","    raise IOError(\"%s not found.\" % path)\n","OSError: x_array.csv not found.\n","Traceback (most recent call last):\n","  File \"matvec.py\", line 25, in <module>\n","    x = np.loadtxt(fname=\"x_array.csv\", delimiter=\",\")\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\", line 1067, in loadtxt\n","    fh = np.lib._datasource.open(fname, 'rt', encoding=encoding)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 193, in open\n","    return ds.open(path, mode, encoding=encoding, newline=newline)\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\", line 533, in open\n","    raise IOError(\"%s not found.\" % path)\n","OSError: x_array.csv not found.\n","-------------------------------------------------------\n","Primary job  terminated normally, but 1 process returned\n","a non-zero exit code.. Per user-direction, the job has been aborted.\n","-------------------------------------------------------\n","--------------------------------------------------------------------------\n","mpirun detected that one or more processes exited with non-zero status, thus causing\n","the job to be terminated. The first process to do so was:\n","\n","  Process name: [[6501,1],0]\n","  Exit code:    1\n","--------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["**Your answer:**  I tried a number of different processes. I tried to use numpy.matmul, @, *, etc. I tried to split the numpy.dot into separate processes, similar to what was being done in matvec.\n","\n","I found that for each rank that the A and x arrays were loaded with new numbers for the matvec function. The y dot production would only run once when the rank is 0 (zero).\n","\n","By using static values stored in files, and then read in. The values stay the same each time, and y_mpi is not loaded with new random values each time the process iterates through the rank. Which produces a smaller value between y and y_mpi.\n","\n"],"metadata":{"id":"YnJERNsaDj9y"}}]}